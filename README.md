# ğŸ‘ï¸ Human Age Prediction Using Deep Learning

## Overview
This project develops a deep learning model to estimate human age from facial images.  
The task is framed as a **regression problem**, where the model predicts a continuous value (age) instead of a class label.

The goal is to build a reliable age-prediction pipeline using modern computer vision techniques, transfer learning, and structured experimentation.
**Best Model:** ğŸ† ResNet50 (MAE â‰ˆ 6.8 years on validation data)

ğŸ”— [View the full notebook here](./notebooks/Human_Age_Prediction.ipynb)

---
## Project Structure

```text
human-age-prediction/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ .gitkeep                
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Human_Age_Prediction.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py           # Data loading and augmentation
â”‚   â”œâ”€â”€ model_builder.py         # ResNet50 regression model
â”‚   â”œâ”€â”€ train.py                 # Training loop and callbacks
â”‚   â””â”€â”€ evaluate.py              # Evaluation utilities and plots
â”‚
â”œâ”€â”€ checkpoints/                 # Saved models 
â”‚
â”œâ”€â”€ run_training.py              # End to end training script
â”œâ”€â”€ environment.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## Project Functionality

### 1. Data Loading and Preprocessing
The dataset includes facial images paired with age labels.  
Key steps:
- Parse directory structure and metadata
- Normalize pixel values
- Resize images for model compatibility
- Split data into training, validation, and test sets
- Use `ImageDataGenerator` for augmentation (rotation, flip, zoom)

### 2. Exploratory Data Analysis
The notebook includes:
- Age distribution histogram
- Random sample of face images with labels
- Basic feature review and dataset sanity checks

### 3. Model Architecture
The final model uses **ResNet50** as a pretrained backbone:
- Frozen convolutional layers
- `GlobalAveragePooling2D`
- Dense hidden layers with dropout
- Final dense output layer with linear activation for regression

This approach leverages transfer learning to improve accuracy with a relatively small dataset.

### 4. Training Workflow
- Loss: Mean Absolute Error (MAE)
- Optimizer: Adam
- Metrics: MAE, MSE
- Early stopping to reduce overfitting
- Checkpointing best-performing model

### 5. Evaluation
Model performance is measured on a held-out test set with:
- Final MAE score  
- Real vs predicted age comparisons  
- Scatterplot and residual analysis  

Example results are included in the notebook.

---

## Key Insights
- Transfer learning significantly improves model convergence and stability.
- Age prediction is sensitive to lighting, pose, and facial expression.
- The model performs best on mid-range ages, with slightly higher error for children and elderly subjects.
- Data augmentation improves generalization by broadening the face representations seen during training.

---

## Results
**Best Model:** ResNet50-based Regression Model  
**Final Performance:**  
- **MAE:** ~5.0â€“7.0 years (varies by dataset and split)
- **MSE:** Included in notebook  
- **Loss Curve:** Smooth convergence with early stopping  
- **Prediction Samples:** Displays true vs predicted ages for random test images

---

## Tech Stack
- Python  
- TensorFlow / Keras  
- NumPy, Pandas  
- Matplotlib, Seaborn  
- Jupyter Notebook  

---

## Author
Rhi Carmel

ğŸ“ [LinkedIn](www.linkedin.com/in/rhiannonfilli)
